from supabase import create_client, Client
from flask import Flask, request, jsonify
from flask_cors import CORS
from bs4 import BeautifulSoup
import requests
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
import time
import chromedriver_autoinstaller  # ğŸ‘ˆ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŒ
import tempfile


app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "https://mg-365.github.io"}})


SUPABASE_URL = "https://vyzpmuvueoqibapjmxrq.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InZ5enBtdXZ1ZW9xaWJhcGpteHJxIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDM5NTEyODgsImV4cCI6MjA1OTUyNzI4OH0.OjVZ_8Qdc3d7a9IIdUvEZ575RZbN2zykfHSsTVGBbM4"
TABLE_NAME = "blog-factory-realdb"

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)






# ì €í’ˆì§ˆ ì²´í¬ìš©, í¬ë¡¬ë“œë¼ì´ë²„ ì„¤ì • í•¨ìˆ˜
def get_headless_driver():
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options

    options = Options()
    options.binary_location = "/usr/bin/chromium"
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920x1080")
    
    # âœ… ì´ ë¼ì¸ì„ ì¶”ê°€í•´ì¤˜!
    import tempfile
    user_data_dir = tempfile.mkdtemp()
    options.add_argument(f'--user-data-dir={user_data_dir}')

    driver = webdriver.Chrome(options=options)
    return driver



def check_daum_status(blog_url):
    try:
        print(f"ğŸ§ª check_daum_status ì‹¤í–‰ ì‹œì‘: {blog_url}")  # ì¶”ê°€
        driver = get_headless_driver()
        search_url = f"https://search.daum.net/search?w=site&q={blog_url}"
        driver.get(search_url)
        time.sleep(2)

        html = driver.page_source
        soup = BeautifulSoup(html, "html.parser")
        posts = soup.select("a.f_link_b")
        ê¸€ìˆ˜ = len(posts)

        site_section = soup.select_one(".f_url")
        ì‚¬ì´íŠ¸ë…¸ì¶œ = False
        if site_section:
            href = site_section.get("href", "")
            ë¹„êµê°’ = blog_url.replace("https://", "").rstrip("/")
            ì‚¬ì´íŠ¸ë…¸ì¶œ = ë¹„êµê°’ in href
        else:
            # a íƒœê·¸ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´ ì‹œë„
            anchors = soup.find_all("a", href=True)
            for a in anchors:
                if blog_url.replace("https://", "").rstrip("/") in a["href"]:
                    ì‚¬ì´íŠ¸ë…¸ì¶œ = True
                    break

        driver.quit()
        return {
            "ê¸€ìˆ˜ì§„ë‹¨": ê¸€ìˆ˜,
            "ì‚¬ì´íŠ¸ë…¸ì¶œ": ì‚¬ì´íŠ¸ë…¸ì¶œ,
            "ê²€ìƒ‰ë§í¬": search_url
        }

    except Exception as e:
        print(f"âŒ [ì§„ë‹¨ ì—ëŸ¬ ë°œìƒ]: {e}")  # ë°˜ë“œì‹œ ì´ ì¤„ ë„£ê¸°
        driver.quit()  # finallyê°€ ì•„ë‹ˆë¯€ë¡œ ì—¬ê¸°ì„œ ê¼­ ì¢…ë£Œì‹œì¼œì•¼ í•¨
        return None





# ì €í’ˆì§ˆ ì²´í¬ íŒŒíŠ¸2
@app.route("/diagnose")
def diagnose_all_blogs():
    print("ğŸ“Œ diagnose ì§„ì…í•¨")
    print("ğŸ’¬ /diagnose ì—”ë“œí¬ì¸íŠ¸ ì‹¤í–‰ë¨")

    result = supabase.table(TABLE_NAME).select("*").execute()
    blogs = result.data
    print(f"ğŸ“Œ ë¸”ë¡œê·¸ {len(blogs)}ê°œ ë¡œë”©ë¨")

    for blog in blogs:
        url = blog.get("name")
        print(f"ğŸ” ë¸”ë¡œê·¸ ëŒ€ìƒ: {url}")
        if not url:
            continue

        print(f"[ì§„ë‹¨ ëŒ€ìƒ] {url}")
        status = check_daum_status(url)
        print(f"[ì§„ë‹¨ ê²°ê³¼] {status}")

        # âœ… ì—ëŸ¬ ë°©ì§€: statusê°€ Noneì´ë©´ ê±´ë„ˆëœ€
        if not status or not isinstance(status, dict):
            print(f"[âŒ ì˜¤ë¥˜] statusê°€ Noneì´ê±°ë‚˜ dict ì•„ë‹˜ â†’ {status}")
            continue

        try:
            supabase.table(TABLE_NAME).update({
                "ê¸€ìˆ˜ì§„ë‹¨": status.get("ê¸€ìˆ˜ì§„ë‹¨", 0),
                "ì‚¬ì´íŠ¸ë…¸ì¶œ": status.get("ì‚¬ì´íŠ¸ë…¸ì¶œ", False),
                "ê²€ìƒ‰ë§í¬": status.get("ê²€ìƒ‰ë§í¬", "")
            }).eq("id", blog["id"]).execute()
            print(f"[ì—…ë°ì´íŠ¸ ì™„ë£Œ] ID={blog['id']}")
        except Exception as e:
            print(f"[ì—…ë°ì´íŠ¸ ì‹¤íŒ¨] ID={blog.get('id')} â†’ {e}")

    return jsonify(
        {"message": f"{len(blogs)}ê°œ ë¸”ë¡œê·¸ ì§„ë‹¨ ì™„ë£Œ"},
        200,
        {'Content-Type': 'application/json; charset=utf-8'}
    )












@app.route("/add", methods=["POST"])
def add_blog():
    data = request.get_json()
    if not data:
        return jsonify({"error": "No data received"}), 400

    try:
        result = supabase.table(TABLE_NAME).insert(data).execute()
        return jsonify({"message": "Blog added!", "data": result.data}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/data", methods=["GET"])
def get_blogs():
    try:
        result = supabase.table(TABLE_NAME).select("*").order("id", desc=True).execute()
        return jsonify(result.data), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/delete', methods=['POST'])
def delete_blog():
    try:
        data = request.get_json()
        blog_id = data.get("id")
        if not blog_id:
            return jsonify({"error": "No blog id provided"}), 400

        result = supabase.table(TABLE_NAME).delete().eq("id", blog_id).execute()
        return jsonify({"message": "Blog deleted", "result": result.data}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# ë¡œì»¬ ê°œë°œìš© (ë°°í¬ì—ëŠ” ì˜í–¥ ì—†ìŒ)
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=10000)


# ì„œë²„ ìŠ¬ë¦½ ë°©ì§€ 10ë¶„ë§ˆë‹¤ í˜¸ì¶œ
@app.route("/ping")
def ping():
    return "pong", 200
